{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)\n",
    "\n",
    "data = pd.read_csv(r\"..\\..\\data\\covtype.csv\")\n",
    "train_df = pd.read_csv(r\"..\\..\\data\\train.csv\")\n",
    "test_df = pd.read_csv(r\"..\\..\\data\\test.csv\")\n",
    "\n",
    "### Feature Engineering\n",
    "# Drop \"ID\"\n",
    "train_df = train_df.drop(columns=[\"Id\"])\n",
    "\n",
    "# Create Labels DF\n",
    "train_labels_df = train_df[[\"Cover_Type\"]]\n",
    "\n",
    "# Drop Labels\n",
    "train_df = train_df.drop(columns=[\"Cover_Type\"])\n",
    "\n",
    "# Build the np arrays\n",
    "train_data = train_df.to_numpy()\n",
    "test_data = test_df.drop(columns=[\"Id\"]).to_numpy()\n",
    "train_labels = train_labels_df.to_numpy().ravel()\n",
    "\n",
    "# Shuffle the input\n",
    "shuffle = np.random.permutation(np.arange(train_data.shape[0]))\n",
    "train_data, train_labels = train_data[shuffle], train_labels[shuffle]\n",
    "\n",
    "# Set some variables to hold dev, and training data.\n",
    "dev_data, dev_labels = train_data[14000:], train_labels[14000:]\n",
    "train_data, train_labels = train_data[:14000], train_labels[:14000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "\n",
    "def print_importances(clf):\n",
    "    importances = np.round(clf.feature_importances_,4)\n",
    "    features = train_df.columns[0:55].to_numpy()\n",
    "    importances_df = pd.DataFrame({'feature':features,'importance':importances})\n",
    "    importances_df = importances_df.sort_values('importance',ascending=False)\n",
    "    importances_df = importances_df[(importances_df.sum(axis=1) != 0)]  \n",
    "    print(importances_df)\n",
    "    \n",
    "def print_structure(clf):\n",
    "    n_nodes = clf.tree_.node_count\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    feature = clf.tree_.feature\n",
    "    threshold = clf.tree_.threshold\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    print(\"The binary tree structure has {n} nodes and has the following tree structure:\\n\".format(n=n_nodes))\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            values = clf.tree_.value[i]\n",
    "            max_value = values.max()\n",
    "            cover_type = np.argmax(values)\n",
    "            print(\"{space}node={node} is a leaf node with max value of {value} and cover type of {ctype}\"\n",
    "                  .format(space=node_depth[i] * \"\\t\", node=i, value=max_value, ctype=cover_type))\n",
    "        else:\n",
    "            print(\"{space}node={node} is a split node: go to node {left} if {feature} <= {threshold} else to node {right}.\".format(\n",
    "                      space=node_depth[i] * \"\\t\",\n",
    "                      node=i,\n",
    "                      left=children_left[i],\n",
    "                      feature=train_df.columns[feature[i]],\n",
    "                      threshold=threshold[i],\n",
    "                      right=children_right[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desicion Tree Score: 65.89%\n",
      "Decision Tree Depth is 4 and has 16 leaves\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 97  23   0   0  15   0  30]\n",
      " [ 38  62   0   0  49   6   4]\n",
      " [  0   1  73  20   9  60   0]\n",
      " [  0   0   7 137   0   9   0]\n",
      " [  0  11   0   0 142  11   0]\n",
      " [  0   0  38  13  11  92   0]\n",
      " [ 27   0   0   0   0   0 135]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "predicted_labels = clf.predict(dev_data)\n",
    "tree_model_score = clf.score(dev_data, dev_labels)\n",
    "depth = clf.get_depth()\n",
    "num_leaves = clf.get_n_leaves()\n",
    "\n",
    "print('Desicion Tree Score: %.2f%%' % (tree_model_score*100))   \n",
    "print('Decision Tree Depth is %d and has %d leaves' % (depth, num_leaves))\n",
    "\n",
    "#plt.figure(figsize=(75,10))\n",
    "#tree.plot_tree(clf, feature_names=train_df.columns, proportion=True)\n",
    "#plt.show()\n",
    "#print_importances(clf)\n",
    "#print_structure(clf)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(dev_labels, predicted_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal value for depth using GridSearchCV method is 30 with accuracy of 0.8053571428571429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15121</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15122</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15123</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15125</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581012</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565892 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cover_Type\n",
       "Id                \n",
       "15121            2\n",
       "15122            2\n",
       "15123            1\n",
       "15124            2\n",
       "15125            2\n",
       "...            ...\n",
       "581008           6\n",
       "581009           6\n",
       "581010           6\n",
       "581011           6\n",
       "581012           6\n",
       "\n",
       "[565892 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "depths = {\"max_depth\": [3, 4, 5, 10, 25, 30]}\n",
    "\n",
    "#Grid search is not working as expected.  Keeps claming the second to last is better even though it is not...\n",
    "grid_search_decision_tree = GridSearchCV(tree.DecisionTreeClassifier(), depths, scoring='accuracy')\n",
    "grid_search_decision_tree.fit(train_data, train_labels)\n",
    "predicted = grid_search_decision_tree.predict(dev_data)\n",
    "optimal_depth = grid_search_decision_tree.best_params_['max_depth']\n",
    "print(\"The optimal value for depth using GridSearchCV method is {depth} with accuracy of {accuracy}\"\n",
    "      .format(depth=optimal_depth, accuracy=metrics.accuracy_score(dev_labels, predicted)))\n",
    "\n",
    "clf_final = tree.DecisionTreeClassifier(max_depth=25, random_state=0)\n",
    "clf_final = clf_final.fit(train_data, train_labels)\n",
    "test_predictions = clf_final.predict(test_data)\n",
    "\n",
    "predictions_dt = pd.DataFrame(data = test_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_dt.to_csv(\"dt_predictions.csv\")  #Kaggle Score of 0.65796\n",
    "predictions_dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted Model Score:  0.8741071428571429\n",
      "Boosted Decision Tree 10-Fold Cross Validation Scores:\n",
      "[0.6875     0.625      0.58928571 0.65178571 0.65178571 0.66071429\n",
      " 0.70535714 0.57142857 0.66964286 0.65178571]\n",
      "Mean:  0.6464285714285715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "bdt = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=20), \n",
    "                              n_estimators=50, learning_rate=1,\n",
    "                              algorithm=\"SAMME\")\n",
    "bdt.fit(train_data, train_labels)\n",
    "boosted_tree_model_score = bdt.score(dev_data, dev_labels)\n",
    "print(\"Boosted Model Score: \", boosted_tree_model_score)\n",
    "\n",
    "boosted_cv_score = cross_val_score(bdt, dev_data, dev_labels, cv = 10)\n",
    "print(\"Boosted Decision Tree 10-Fold Cross Validation Scores:\")\n",
    "print(boosted_cv_score)\n",
    "print(\"Mean: \", boosted_cv_score.mean())\n",
    "\n",
    "\n",
    "boosted_predictions = bdt.predict(test_data)\n",
    "predictions_bdt = pd.DataFrame(data = boosted_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_bdt.to_csv(\"bdt_predictions.csv\")  #Kaggle Score of 0.74566 increase of 10%!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score:  0.8651785714285715\n",
      "Random Forest 10-Fold Cross Validation Scores:\n",
      "[0.73214286 0.76785714 0.75892857 0.69642857 0.70535714 0.76785714\n",
      " 0.76785714 0.72321429 0.71428571 0.80357143]\n",
      "Mean:  0.7437500000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd = RandomForestClassifier(criterion=\"entropy\", max_depth=20, bootstrap=True, random_state=0)\n",
    "rnd.fit(train_data, train_labels)\n",
    "random_forest_score = rnd.score(dev_data, dev_labels)\n",
    "print(\"Random Forest Score: \" , random_forest_score)\n",
    "\n",
    "random_forest_cv_score = cross_val_score(rnd, dev_data, dev_labels, cv = 10)\n",
    "print(\"Random Forest 10-Fold Cross Validation Scores:\")\n",
    "print(random_forest_cv_score)\n",
    "print(\"Mean: \", random_forest_cv_score.mean())\n",
    "\n",
    "rf_predictions = rnd.predict(test_data)\n",
    "predictions_rf = pd.DataFrame(data = rf_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_rf.to_csv(\"rf_predictions.csv\")  #Kaggle Score of 0.73459\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Score:  0.8839285714285714\n",
      "Random Forest 10-Fold Cross Validation Scores: \n",
      "[0.75       0.77678571 0.75892857 0.69642857 0.75       0.79464286\n",
      " 0.75892857 0.76785714 0.78571429 0.80357143]\n",
      "Mean:  0.7642857142857143\n"
     ]
    }
   ],
   "source": [
    "### Warning - this runs VERY slow with n_estimators at 1000\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ex = ExtraTreesClassifier(random_state=0, n_estimators = 1000) \n",
    "ex.fit(train_data, train_labels)\n",
    "extra_trees_score = ex.score(dev_data, dev_labels)\n",
    "print(\"Extra Trees Score: \", extra_trees_score)\n",
    "\n",
    "print(\"Random Forest 10-Fold Cross Validation Scores: \")\n",
    "extra_trees_cv_score = cross_val_score(ex, dev_data, dev_labels, cv = 10)\n",
    "print(extra_trees_cv_score)\n",
    "print(\"Mean: \", extra_trees_cv_score.mean())\n",
    "\n",
    "ex_predictions = ex.predict(test_data)\n",
    "predictions_ex = pd.DataFrame(data = ex_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_ex.to_csv(\"ex_predictions.csv\")  #Kaggle Score of 0.75287\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted Random Forest Score:  0.8705357142857143\n",
      "Boosted Random Forest 10-Fold Cross Validation Scores:\n",
      "[0.70535714 0.76785714 0.75       0.72321429 0.70535714 0.75892857\n",
      " 0.75892857 0.75892857 0.74107143 0.8125    ]\n",
      "Mean:  0.7482142857142857\n"
     ]
    }
   ],
   "source": [
    "### Boosting with Random Forest\n",
    "brf = AdaBoostClassifier(RandomForestClassifier(criterion=\"entropy\", max_depth=20, bootstrap=True, random_state=0), \n",
    "                              n_estimators=50, learning_rate=1,\n",
    "                              algorithm=\"SAMME\")\n",
    "brf.fit(train_data, train_labels)\n",
    "boosted_forest_score = brf.score(dev_data, dev_labels)\n",
    "print(\"Boosted Random Forest Score: \", boosted_forest_score)\n",
    "\n",
    "boosted_forest_cv_score = cross_val_score(brf, dev_data, dev_labels, cv = 10)\n",
    "print(\"Boosted Random Forest 10-Fold Cross Validation Scores:\")\n",
    "print(boosted_forest_cv_score)\n",
    "print(\"Mean: \", boosted_forest_cv_score.mean())\n",
    "\n",
    "boosted_forest_predictions = brf.predict(test_data)\n",
    "predictions_brf = pd.DataFrame(data = boosted_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_brf.to_csv(\"brf_predictions.csv\")  #Kaggle Score of 0.74566"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
