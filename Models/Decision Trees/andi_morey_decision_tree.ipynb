{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)\n",
    "\n",
    "data = pd.read_csv(r\"..\\..\\data\\covtype.csv\")\n",
    "train_df = pd.read_csv(r\"..\\..\\data\\train.csv\")\n",
    "test_df = pd.read_csv(r\"..\\..\\data\\test.csv\")\n",
    "\n",
    "# Build the np arrays\n",
    "train_data = train_df.to_numpy()\n",
    "test_data = test_df.to_numpy()\n",
    "\n",
    "# Get last column for train labels\n",
    "train_labels = train_data[ :,55]\n",
    "\n",
    "#Remove last column from train_data because that is the labels\n",
    "train_data = np.delete(train_data, 55, axis=1)\n",
    "\n",
    "# Shuffle the input\n",
    "shuffle = np.random.permutation(np.arange(train_data.shape[0]))\n",
    "train_data, train_labels = train_data[shuffle], train_labels[shuffle]\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "#test_data, test_labels = train_data[0:2000,:], train_labels[0:2000]\n",
    "dev_data, dev_labels = train_data[2000:14000,:], train_labels[2000:14000]\n",
    "mini_train_data, mini_train_labels = train_data[14000:15000,:], train_labels[14000:15000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "\n",
    "def print_importances(clf):\n",
    "    importances = np.round(clf.feature_importances_,4)\n",
    "    features = train_df.columns[0:55].to_numpy()\n",
    "    importances_df = pd.DataFrame({'feature':features,'importance':importances})\n",
    "    importances_df = importances_df.sort_values('importance',ascending=False)\n",
    "    importances_df = importances_df[(importances_df.sum(axis=1) != 0)]  \n",
    "    print(importances_df)\n",
    "    \n",
    "def print_structure(clf):\n",
    "    n_nodes = clf.tree_.node_count\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    feature = clf.tree_.feature\n",
    "    threshold = clf.tree_.threshold\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    print(\"The binary tree structure has {n} nodes and has the following tree structure:\\n\".format(n=n_nodes))\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            values = clf.tree_.value[i]\n",
    "            max_value = values.max()\n",
    "            cover_type = np.argmax(values)\n",
    "            print(\"{space}node={node} is a leaf node with max value of {value} and cover type of {ctype}\"\n",
    "                  .format(space=node_depth[i] * \"\\t\", node=i, value=max_value, ctype=cover_type))\n",
    "        else:\n",
    "            print(\"{space}node={node} is a split node: go to node {left} if {feature} <= {threshold} else to node {right}.\".format(\n",
    "                      space=node_depth[i] * \"\\t\",\n",
    "                      node=i,\n",
    "                      left=children_left[i],\n",
    "                      feature=train_df.columns[feature[i]],\n",
    "                      threshold=threshold[i],\n",
    "                      right=children_right[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desicion Tree Score: 64.74%\n",
      "Decision Tree Depth is 4 and has 16 leaves\n",
      "Confusion Matrix:\n",
      "\n",
      "[[1068  286    0    0  148    6  187]\n",
      " [ 420  641    4    1  569   73   13]\n",
      " [   0    1  717  326  112  565    0]\n",
      " [   0    0   92 1529    0  103    0]\n",
      " [   0   81    7    0 1530   94    0]\n",
      " [   0    8  407  206  144  933    0]\n",
      " [ 371    1    0    0    6    0 1351]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "predicted_labels = clf.predict(dev_data)\n",
    "tree_model_score = clf.score(dev_data, dev_labels)\n",
    "depth = clf.get_depth()\n",
    "num_leaves = clf.get_n_leaves()\n",
    "\n",
    "print('Desicion Tree Score: %.2f%%' % (tree_model_score*100))   \n",
    "print('Decision Tree Depth is %d and has %d leaves' % (depth, num_leaves))\n",
    "\n",
    "#plt.figure(figsize=(75,10))\n",
    "#tree.plot_tree(clf, feature_names=train_df.columns, proportion=True)\n",
    "#plt.show()\n",
    "#print_importances(clf)\n",
    "#print_structure(clf)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(dev_labels, predicted_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal value for depth using GridSearchCV method is 30 with accuracy of 0.9995\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15121</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15122</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15123</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15125</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581012</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565892 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cover_Type\n",
       "Id                \n",
       "15121            5\n",
       "15122            5\n",
       "15123            5\n",
       "15124            5\n",
       "15125            5\n",
       "...            ...\n",
       "581008           3\n",
       "581009           3\n",
       "581010           3\n",
       "581011           3\n",
       "581012           6\n",
       "\n",
       "[565892 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "depths = {\"max_depth\": [3, 4, 5, 10, 25, 30]}\n",
    "\n",
    "#Grid search is not working as expected.  Keeps claming the second to last is better even though it is not...\n",
    "grid_search_decision_tree = GridSearchCV(tree.DecisionTreeClassifier(), depths, scoring='accuracy')\n",
    "grid_search_decision_tree.fit(train_data, train_labels)\n",
    "predicted = grid_search_decision_tree.predict(dev_data)\n",
    "optimal_depth = grid_search_decision_tree.best_params_['max_depth']\n",
    "print(\"The optimal value for depth using GridSearchCV method is {depth} with accuracy of {accuracy}\"\n",
    "      .format(depth=optimal_depth, accuracy=metrics.accuracy_score(dev_labels, predicted)))\n",
    "\n",
    "clf_final = tree.DecisionTreeClassifier(max_depth=25, random_state=0)\n",
    "clf_final = clf_final.fit(train_data, train_labels)\n",
    "test_predictions = clf_final.predict(test_df)\n",
    "\n",
    "predictions_dt = pd.DataFrame(data = test_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_dt.to_csv(\"dt_predictions.csv\")  #Kaggle Score of 0.59266\n",
    "predictions_dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted Model Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "boosted_decision_tree = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=20), \n",
    "                              n_estimators=50, learning_rate=1,\n",
    "                              algorithm=\"SAMME\")\n",
    "boosted_decision_tree.fit(train_data, train_labels)\n",
    "boosted_tree_model_score = boosted_decision_tree.score(dev_data, dev_labels)\n",
    "print(\"Boosted Model Score: \", boosted_tree_model_score)\n",
    "\n",
    "boosted_predictions = boosted_decision_tree.predict(test_df)\n",
    "predictions_bdt = pd.DataFrame(data = boosted_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_bdt.to_csv(\"bdt_predictions.csv\")  #Kaggle Score of 0.69381 increase of 10%!!!\n",
    "#predictions_bdt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8543333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd = RandomForestClassifier(criterion=\"entropy\", max_depth=20, bootstrap=True, random_state=0)\n",
    "rnd.fit(train_data, train_labels)\n",
    "print(cross_val_score(rnd, dev_data, dev_labels, cv = 3).mean())\n",
    "\n",
    "rf_predictions = rnd.predict(test_df)\n",
    "predictions_rf = pd.DataFrame(data = rf_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_rf.to_csv(\"rf_predictions.csv\")  #Kaggle Score of 0.71587\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8525\n"
     ]
    }
   ],
   "source": [
    "### Warning - this runs VERY slow with n_estimators at 1000\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ex = ExtraTreesClassifier(random_state=0, n_estimators = 1000) \n",
    "\n",
    "ex.fit(train_data, train_labels)\n",
    "print(cross_val_score(ex, dev_data, dev_labels, cv = 3).mean())\n",
    "\n",
    "ex_predictions = ex.predict(test_df)\n",
    "predictions_ex = pd.DataFrame(data = ex_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_ex.to_csv(\"ex_predictions.csv\")  #Kaggle Score of 0.72549\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}