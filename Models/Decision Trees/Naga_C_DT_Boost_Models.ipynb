{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with Grid Search and Adaboost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the provided dataset and understand the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset contains 15120 observations with 56 features for each observation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   1       2596      51      3                               258   \n",
       "1   2       2590      56      2                               212   \n",
       "2   3       2804     139      9                               268   \n",
       "3   4       2785     155     18                               242   \n",
       "4   5       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
       "0            221             232            148  ...            0   \n",
       "1            220             235            151  ...            0   \n",
       "2            234             238            135  ...            0   \n",
       "3            238             238            122  ...            0   \n",
       "4            220             234            150  ...            0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0           5  \n",
       "1            0            0            0           5  \n",
       "2            0            0            0           2  \n",
       "3            0            0            0           2  \n",
       "4            0            0            0           5  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data set provided from the Kaggle competition website\n",
    "\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "print(\"The training dataset contains {0} observations with {1} features for each observation.\".\\\n",
    "    format(train_df.shape[0], train_df.shape[1]))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the training data into train and dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1512, 54) (13608, 54)\n",
      "(565892, 54)\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into train and dev data set.\n",
    "# Read the training data into X and y\n",
    "train_file = open(\"data/train.csv\")\n",
    "column_names_train = train_file.readline()\n",
    "data = np.loadtxt(train_file, delimiter=\",\")\n",
    "\n",
    "y, X = data[:, -1].astype('u1'), data[:, :-1]\n",
    "\n",
    "# Shuffle the data, but make sure that the features and accompanying labels stay in sync.\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "# Split the training data into 90% training data and 10% dev data\n",
    "train_size = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Discard 1st feature (ID number that doesn't provide info about the label)\n",
    "y_train, X_train = y[:train_size], X[:train_size, 1:]\n",
    "y_dev, X_dev = y[train_size:], X[train_size:, 1:]\n",
    "print(X_dev.shape, X_train.shape)\n",
    "\n",
    "# Read the test data and store in X_test\n",
    "test_file = open(\"data/test.csv\")\n",
    "column_names_test = test_file.readline()\n",
    "data_test = np.loadtxt(test_file, delimiter=\",\")\n",
    "\n",
    "# Save the test data in X_test. Test data does not have the 1st feature\n",
    "X_test = data_test\n",
    "X_test = X_test[:, 1:]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15121</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15122</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15123</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15125</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581012</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565892 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cover_Type\n",
       "Id                \n",
       "15121            2\n",
       "15122            2\n",
       "15123            1\n",
       "15124            1\n",
       "15125            1\n",
       "...            ...\n",
       "581008           3\n",
       "581009           3\n",
       "581010           3\n",
       "581011           3\n",
       "581012           3\n",
       "\n",
       "[565892 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import training data from relative filepath\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# extract training data except labels and ID column\n",
    "train_df = data.loc[:, (data.columns != \"Cover_Type\") & (data.columns != \"Id\")]\n",
    "\n",
    "# extract labels from training data\n",
    "train_labels_df = data.loc[:, \"Cover_Type\"]\n",
    "\n",
    "# import test data from relative filepath\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# extract test data except ID column\n",
    "test_df = test_data.loc[:, test_data.columns != \"Id\"]\n",
    "\n",
    "# train model using K-NN and the mini_train data and mini_train_labels\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "knn_model.fit(train_df, train_labels_df)\n",
    "\n",
    "# Supply the test_df to knn_model and create predictions\n",
    "predictions = knn_model.predict(test_df)\n",
    "\n",
    "# converts predictions from np array to pd dataframe\n",
    "predictions_df = pd.DataFrame(data = predictions, index = test_data.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal criterion is entropy\n",
      "The optimal maximum number of features is 52\n",
      "The optimal maximum depth of the tree is 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.64      0.66       220\n",
      "           2       0.64      0.61      0.63       208\n",
      "           3       0.79      0.74      0.76       220\n",
      "           4       0.94      0.94      0.94       212\n",
      "           5       0.88      0.93      0.90       227\n",
      "           6       0.77      0.83      0.79       206\n",
      "           7       0.89      0.94      0.92       219\n",
      "\n",
      "    accuracy                           0.80      1512\n",
      "   macro avg       0.80      0.80      0.80      1512\n",
      "weighted avg       0.80      0.80      0.80      1512\n",
      "\n",
      "0.8029100529100529\n"
     ]
    }
   ],
   "source": [
    "criterion = ['gini', 'entropy']\n",
    "max_features = [2, 5, 10, 20, 50, 52, 54]\n",
    "max_depth = [5, 10, 20, 30, 40]\n",
    "\n",
    "'''\n",
    "Grid of parameters with a discrete number of values for each. Can be used to iterate over parameter value \n",
    "combinations with the Python built-in function iter. The order of the generated parameter combinations is \n",
    "deterministic.\n",
    "'''\n",
    "param_grid = {'criterion': criterion, 'max_features': max_features, 'max_depth': max_depth}\n",
    "\n",
    "# Find best parameter for the decision tree classifier using the param_grid and gridsearch\n",
    "# Fit this decision tree using the trianing data\n",
    "\n",
    "best_param_DT = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring='accuracy')\n",
    "best_param_DT.fit(X_train, y_train)\n",
    "\n",
    "# Find optimal criterion between gini and entropy\n",
    "optimal_criterion_DT = best_param_DT.best_params_['criterion']\n",
    "print('The optimal criterion is {0}'.format(optimal_criterion_DT))\n",
    "\n",
    "# Find optimal max_features\n",
    "optimal_max_features_DT = best_param_DT.best_params_['max_features']\n",
    "print('The optimal maximum number of features is {0}'.format(optimal_max_features_DT))\n",
    "\n",
    "# Find optimal max depth for the decision tree\n",
    "optimal_max_depth_DT = best_param_DT.best_params_['max_depth']\n",
    "print('The optimal maximum depth of the tree is {0}'.format(optimal_max_depth_DT))\n",
    "\n",
    "# Pass the optimal criterion, max_features, and max_depth to develop the model and fit to the train data\n",
    "DT = DecisionTreeClassifier(criterion=optimal_criterion_DT, max_features=optimal_max_features_DT, \n",
    "                            max_depth=optimal_max_depth_DT, random_state=0)\n",
    "DT.fit(X_train, y_train)\n",
    "\n",
    "# Using the dev data predict the y using decision tree algorithm\n",
    "y_dev_dec = DT.predict(X_dev)\n",
    "print(metrics.classification_report(y_dev, y_dev_dec))\n",
    "print(metrics.accuracy_score(y_dev, y_dev_dec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost\n",
    "\n",
    "AdaBoost is best used to boost the performance of decision trees on binary classification problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (adaboost with decision trees NORMAL new feature): 0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.74      0.75       220\n",
      "           2       0.71      0.67      0.69       208\n",
      "           3       0.78      0.78      0.78       220\n",
      "           4       0.97      0.92      0.94       212\n",
      "           5       0.87      0.90      0.88       227\n",
      "           6       0.79      0.86      0.83       206\n",
      "           7       0.94      0.95      0.95       219\n",
      "\n",
      "    accuracy                           0.83      1512\n",
      "   macro avg       0.83      0.83      0.83      1512\n",
      "weighted avg       0.83      0.83      0.83      1512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_features = column_names_test.split(\",\")\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=30), n_estimators=500, learning_rate=1.0)\n",
    "abc.fit(X_train, y_train)\n",
    "y_pred = abc.predict(X_dev)\n",
    "print('Accuracy (adaboost with decision trees NORMAL new feature):', abc.score(X_dev,y_dev))\n",
    "print(classification_report(y_dev,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Decision tree and Adaboost to get the models\n",
    "DT.fit(train_df, train_labels_df)\n",
    "abc.fit(train_df, train_labels_df)\n",
    "\n",
    "# Supply the test_df to models and create predictions\n",
    "predictions_DT = DT.predict(test_df)\n",
    "predictions_abc = abc.predict(test_df)\n",
    "\n",
    "# converts predictions from np array to pd dataframe\n",
    "predictions_DT_df = pd.DataFrame(data = predictions_DT, index = test_data.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_abc_df = pd.DataFrame(data = predictions_abc, index = test_data.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "\n",
    "# outputs to csv file\n",
    "predictions_DT_df.to_csv(\"DT_predictions.csv\")\n",
    "predictions_abc_df.to_csv(\"abc_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When submitted DT into Kaggle the score was 0.672\n",
    "\n",
    "# Post adaboost the score in Kaggle was 0.70"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
