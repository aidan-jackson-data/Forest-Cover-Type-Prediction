{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the provided dataset and understand the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset contains 15120 observations with 56 features for each observation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   1       2596      51      3                               258   \n",
       "1   2       2590      56      2                               212   \n",
       "2   3       2804     139      9                               268   \n",
       "3   4       2785     155     18                               242   \n",
       "4   5       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
       "0            221             232            148  ...            0   \n",
       "1            220             235            151  ...            0   \n",
       "2            234             238            135  ...            0   \n",
       "3            238             238            122  ...            0   \n",
       "4            220             234            150  ...            0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0           5  \n",
       "1            0            0            0           5  \n",
       "2            0            0            0           2  \n",
       "3            0            0            0           2  \n",
       "4            0            0            0           5  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data set provided from the Kaggle competition website\n",
    "\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "print(\"The training dataset contains {0} observations with {1} features for each observation.\".\\\n",
    "    format(train_df.shape[0], train_df.shape[1]))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the training data into train and dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1512, 54) (13608, 54)\n",
      "(565892, 54)\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into train and dev data set.\n",
    "# Read the training data into X and y\n",
    "train_file = open(\"data/train.csv\")\n",
    "column_names_train = train_file.readline()\n",
    "data = np.loadtxt(train_file, delimiter=\",\")\n",
    "\n",
    "y, X = data[:, -1].astype('u1'), data[:, :-1]\n",
    "\n",
    "# Shuffle the data, but make sure that the features and accompanying labels stay in sync.\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, y = X[shuffle], y[shuffle]\n",
    "\n",
    "# Split the training data into 90% training data and 10% dev data\n",
    "train_size = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Discard 1st feature (ID number that doesn't provide info about the label)\n",
    "y_train, X_train = y[:train_size], X[:train_size, 1:]\n",
    "y_dev, X_dev = y[train_size:], X[train_size:, 1:]\n",
    "print(X_dev.shape, X_train.shape)\n",
    "\n",
    "# Read the test data and store in X_test\n",
    "test_file = open(\"data/test.csv\")\n",
    "column_names_test = test_file.readline()\n",
    "data_test = np.loadtxt(test_file, delimiter=\",\")\n",
    "\n",
    "# Save the test data in X_test. Test data does not have the 1st feature\n",
    "X_test = data_test\n",
    "X_test = X_test[:, 1:]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "For k: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.67      0.73       220\n",
      "           2       0.72      0.66      0.69       208\n",
      "           3       0.85      0.81      0.83       220\n",
      "           4       0.94      0.96      0.95       212\n",
      "           5       0.89      0.96      0.93       227\n",
      "           6       0.83      0.91      0.87       206\n",
      "           7       0.90      0.99      0.95       219\n",
      "\n",
      "    accuracy                           0.85      1512\n",
      "   macro avg       0.85      0.85      0.85      1512\n",
      "weighted avg       0.85      0.85      0.85      1512\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "For k: 1 Match: 1291 Mismatch: 221 Total: 1512 Accuracy: 0.854\n",
      "For k: 3 Match: 1258 Mismatch: 254 Total: 1512 Accuracy: 0.832\n",
      "For k: 5 Match: 1236 Mismatch: 276 Total: 1512 Accuracy: 0.817\n",
      "For k: 7 Match: 1214 Mismatch: 298 Total: 1512 Accuracy: 0.803\n",
      "For k: 9 Match: 1200 Mismatch: 312 Total: 1512 Accuracy: 0.794\n",
      "For k: 11 Match: 1168 Mismatch: 344 Total: 1512 Accuracy: 0.772\n",
      "For k: 13 Match: 1147 Mismatch: 365 Total: 1512 Accuracy: 0.759\n",
      "For k: 15 Match: 1159 Mismatch: 353 Total: 1512 Accuracy: 0.767\n",
      "For k: 17 Match: 1144 Mismatch: 368 Total: 1512 Accuracy: 0.757\n",
      "For k: 19 Match: 1145 Mismatch: 367 Total: 1512 Accuracy: 0.757\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "The optimal value for k using GridSearchCV method is 1\n"
     ]
    }
   ],
   "source": [
    "def P2(k_values):\n",
    "\n",
    "    '''\n",
    "    KNN can be used for both classification and regression predictive problems. However, it is more widely \n",
    "    used in classification problems in the industry. The classification is based on the class of the neighbors.\n",
    "    With increasing k value or more neighbors considered for classification, the boundary becomes smooth. The \n",
    "    training error rate and the validation error rate are two parameters we need to access different K-value. \n",
    "    In this code, we are studying the effect of k-value.'''\n",
    "    \n",
    "    # We use KNeighborsClassifier() from the Scikit-Learn Python library to start. \n",
    "    # This function takes many arguments, but we will only have to worry about a few in this example. \n",
    "    # Specifically, we will only be passing a value for the n_neighbors argument (this is the k value). \n",
    "    # For weights we will use default value as uniform, meaning each of the k points is equally weighted\n",
    "    # The algorithm argument will also be left at its default value of auto\n",
    "    \n",
    "    # Run through the 5 k_values passed in (1, 3, 5, 7, and 9)\n",
    "\n",
    "    accuracy = []\n",
    "    for k in k_values:\n",
    "        \n",
    "        # train model using K-NN and the mini_train data and mini_train_labels\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "        knn_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Use the knn model developed with mini_train_data and predict lables\n",
    "        # Supply dev_data to the model and get the predicted labels\n",
    "        prediction_labels = knn_model.predict(X_dev)\n",
    "        \n",
    "        # Determine the score\n",
    "        score = knn_model.score(X_dev, y_dev)\n",
    "        accuracy.append(score)\n",
    "        \n",
    "        # Check number of match and mismatch predictions. Are predicted and dev labels matching?\n",
    "        # If predicted labels for dev data matches dev labels, call it a match. If not, it is mismatch\n",
    "        match = []\n",
    "        mismatch = []\n",
    "        match = (prediction_labels == y_dev)\n",
    "        mismatch = (prediction_labels != y_dev)\n",
    "        total = np.sum(match) + np.sum(mismatch)\n",
    "\n",
    "        # The classification report visualizer displays the precision, recall, F1 for model\n",
    "        # Precision can be seen as a measure of a classifierâ€™s exactness. \n",
    "        # For each class, it is defined as the ratio of true positives to the sum of true and false positives. \n",
    "        # Recall is a measure of the ability of a classifier to correctly find all positive instances. \n",
    "        # The F1 score is a weighted harmonic mean of precision and recall \n",
    "        # For F1, the best score is 1.0 and the worst is 0.0.\n",
    "        # Support is the number of actual occurrences of the class in the specified dataset. \n",
    "\n",
    "        # Printing the output\n",
    "        if (k == 1):\n",
    "            print(\"\\n----------------------------------------------------\\n\")\n",
    "            print(\"For k: %d\" % k)\n",
    "            print(classification_report(y_dev, prediction_labels))\n",
    "            print(\"\\n----------------------------------------------------\\n\")\n",
    "            print(\"For k: %d Match: %d Mismatch: %d Total: %d Accuracy: %.3f\"\n",
    "                  % (k, np.sum(match), np.sum(mismatch), np.sum(total), score))\n",
    "        else:\n",
    "            print(\"For k: %d Match: %d Mismatch: %d Total: %d Accuracy: %.3f\"\n",
    "                  % (k, np.sum(match), np.sum(mismatch), np.sum(total), score))\n",
    "            \n",
    "    return accuracy\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "accuracy = P2(k_values)\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "(\"Plot the accuracy against k-values using the manual method\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(k_values, accuracy, marker='o')\n",
    "plt.xlabel(\"k Values\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.title('F1 score per value of k')\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, max(k_values)+1])\n",
    "plt.xticks(np.arange(0, max(k_values)+1, 1))\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "plt.axvline(x=1, linewidth=1, linestyle='--', color='red')\n",
    "plt.axhline(y=max(accuracy), linewidth=1, linestyle='--', color='red')\n",
    "plt.show()\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Use Gridsearch method to estimate optimal value of k and accuracy\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "# Estimate by cross-validation the optimal number of neighbors (k)\n",
    "# Based on the previous results, we know k=1. So, try till k=20\n",
    "k = {'n_neighbors': np.concatenate([np.arange(1, 20+1)]).tolist()}\n",
    "\n",
    "best_param_kNN = GridSearchCV(KNeighborsClassifier(), k, scoring='accuracy')\n",
    "best_param_kNN.fit(X_train, y_train)\n",
    "optimal_k = best_param_kNN.best_params_['n_neighbors']\n",
    "print(\"\\n\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(\"The optimal value for k using GridSearchCV method is {0}\".format(optimal_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using K-NN model which cover types are most confused?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ Confusion Matrix -----------\n",
      "\n",
      "[[148  41   0   0   9   1  21]\n",
      " [ 34 138  12   0  14   8   2]\n",
      " [  0   4 178  12   1  25   0]\n",
      " [  0   0   4 204   0   4   0]\n",
      " [  0   7   0   0 219   1   0]\n",
      " [  0   1  15   1   2 187   0]\n",
      " [  2   0   0   0   0   0 217]]\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Most confused cover types are: 0 and 1, with 75 number of errors.\n",
      "\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build a model using KNN-1. Use train set to train the model\n",
    "confusion_model = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "confusion_model.fit(X_train, y_train)\n",
    "\n",
    "# Create the confusion matrix for the dev_data\n",
    "# Confusion matrix prints comparison of dev labels against predicted labels\n",
    "predicted_labels = confusion_model.predict(X_dev)\n",
    "confusion = confusion_matrix(y_dev, predicted_labels)\n",
    "print(\"\\n------------ Confusion Matrix -----------\\n\")\n",
    "print(confusion)\n",
    "\n",
    "# From matrix find out most confused digits\n",
    "# For the confusion matrix rows and columns, iterate through the top part\n",
    "# of the triangle and sum the pair of indices to find most errors between pairs\n",
    "confused_row, confused_column, confused_count = 0, 1, 0\n",
    "rows, columns = np.shape(confusion)\n",
    "for i in range(rows):\n",
    "    for j in range(i+1, columns):\n",
    "        errors = confusion[i][j] + confusion[j][i]\n",
    "        if errors > confused_count:\n",
    "            confused_row = i\n",
    "            confused_column = j\n",
    "            confused_count = errors\n",
    "    \n",
    "# We print a combined number of errors. It is errors between pairs\n",
    "    \n",
    "print(\"---------------------------------------------------------------\\n\")\n",
    "print(\"Most confused cover types are: \" + str(confused_row) + \" and \" + str(confused_column) + \n",
    "      \", with \" + str(confused_count) + \" number of errors.\\n\")\n",
    "print(\"---------------------------------------------------------------\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15121</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15122</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15123</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15125</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581012</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565892 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cover_Type\n",
       "Id                \n",
       "15121            2\n",
       "15122            2\n",
       "15123            1\n",
       "15124            1\n",
       "15125            1\n",
       "...            ...\n",
       "581008           3\n",
       "581009           3\n",
       "581010           3\n",
       "581011           3\n",
       "581012           3\n",
       "\n",
       "[565892 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import training data from relative filepath\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# extract training data except labels and ID column\n",
    "train_df = data.loc[:, (data.columns != \"Cover_Type\") & (data.columns != \"Id\")]\n",
    "\n",
    "# extract labels from training data\n",
    "train_labels_df = data.loc[:, \"Cover_Type\"]\n",
    "\n",
    "# import test data from relative filepath\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# extract test data except ID column\n",
    "test_df = test_data.loc[:, test_data.columns != \"Id\"]\n",
    "\n",
    "# train model using K-NN and the mini_train data and mini_train_labels\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "knn_model.fit(train_df, train_labels_df)\n",
    "\n",
    "# Supply the test_df to knn_model and create predictions\n",
    "predictions = knn_model.predict(test_df)\n",
    "\n",
    "# converts predictions from np array to pd dataframe\n",
    "predictions_df = pd.DataFrame(data = predictions, index = test_data.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs to csv file\n",
    "predictions_df.to_csv(\"knn_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When submitted into kaggle, it provided a score of 0.71016 a leadership board rank of 1179."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5906084656084656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.56      0.55       220\n",
      "           2       0.50      0.42      0.46       208\n",
      "           3       0.50      0.40      0.44       220\n",
      "           4       0.71      0.78      0.74       212\n",
      "           5       0.62      0.69      0.65       227\n",
      "           6       0.45      0.47      0.46       206\n",
      "           7       0.75      0.80      0.78       219\n",
      "\n",
      "    accuracy                           0.59      1512\n",
      "   macro avg       0.58      0.59      0.58      1512\n",
      "weighted avg       0.58      0.59      0.58      1512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Develop Gaussian Naive Bayes model\n",
    "\n",
    "'''Gaussian Naive Bayes is a variant of Naive Bayes that follows Gaussian normal distribution \n",
    "and supports continuous data'''\n",
    "\n",
    "GNB_model = GaussianNB()\n",
    "GNB_model.fit(X_train[:,:10], y_train)\n",
    "\n",
    "# Predict the labels by passing the dev data that was split out from train data\n",
    "dev_predicted_labels = GNB_model.predict(X_dev[:,:10])\n",
    "\n",
    "# Print accuracy scores\n",
    "print(metrics.accuracy_score(y_true=y_dev, y_pred=dev_predicted_labels))\n",
    "print(metrics.classification_report(y_dev, dev_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15121</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15122</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15123</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15125</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581012</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565892 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cover_Type\n",
       "Id                \n",
       "15121            2\n",
       "15122            2\n",
       "15123            1\n",
       "15124            2\n",
       "15125            2\n",
       "...            ...\n",
       "581008           3\n",
       "581009           3\n",
       "581010           3\n",
       "581011           3\n",
       "581012           3\n",
       "\n",
       "[565892 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Develop Gaussian Naive Bayes model\n",
    "GNB_model = GaussianNB()\n",
    "GNB_model.fit(train_df, train_labels_df)\n",
    "\n",
    "# Supply the test_df to GNB_model and create predictions\n",
    "predictions = GNB_model.predict(test_df)\n",
    "\n",
    "# converts predictions from np array to pd dataframe\n",
    "predictions_NB_df = pd.DataFrame(data = predictions, index = test_data.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "\n",
    "predictions_NB_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs to csv file\n",
    "predictions_NB_df.to_csv(\"nb_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When submitted into kaggle, it provided a score of 0.42149 much lower than K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal criterion is entropy\n",
      "The optimal maximum number of features is 52\n",
      "The optimal maximum depth of the tree is 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.69       220\n",
      "           2       0.65      0.58      0.61       208\n",
      "           3       0.80      0.76      0.78       220\n",
      "           4       0.95      0.96      0.95       212\n",
      "           5       0.85      0.93      0.89       227\n",
      "           6       0.76      0.80      0.78       206\n",
      "           7       0.90      0.95      0.92       219\n",
      "\n",
      "    accuracy                           0.81      1512\n",
      "   macro avg       0.80      0.81      0.80      1512\n",
      "weighted avg       0.80      0.81      0.80      1512\n",
      "\n",
      "0.8075396825396826\n"
     ]
    }
   ],
   "source": [
    "criterion = ['gini', 'entropy']\n",
    "max_features = [2, 5, 10, 20, 50, 52, 54]\n",
    "max_depth = [5, 10, 20, 30, 40]\n",
    "\n",
    "'''\n",
    "Grid of parameters with a discrete number of values for each. Can be used to iterate over parameter value \n",
    "combinations with the Python built-in function iter. The order of the generated parameter combinations is \n",
    "deterministic.\n",
    "'''\n",
    "param_grid = {'criterion': criterion, 'max_features': max_features, 'max_depth': max_depth}\n",
    "\n",
    "# Find best parameter for the decision tree classifier using the param_grid and gridsearch\n",
    "# Fit this decision tree using the trianing data\n",
    "\n",
    "best_param_DT = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring='accuracy')\n",
    "best_param_DT.fit(X_train, y_train)\n",
    "\n",
    "# Find optimal criterion between gini and entropy\n",
    "optimal_criterion_DT = best_param_DT.best_params_['criterion']\n",
    "print('The optimal criterion is {0}'.format(optimal_criterion_DT))\n",
    "\n",
    "# Find optimal max_features\n",
    "optimal_max_features_DT = best_param_DT.best_params_['max_features']\n",
    "print('The optimal maximum number of features is {0}'.format(optimal_max_features_DT))\n",
    "\n",
    "# Find optimal max depth for the decision tree\n",
    "optimal_max_depth_DT = best_param_DT.best_params_['max_depth']\n",
    "print('The optimal maximum depth of the tree is {0}'.format(optimal_max_depth_DT))\n",
    "\n",
    "# Pass the optimal criterion, max_features, and max_depth to develop the model and fit to the train data\n",
    "DT = DecisionTreeClassifier(criterion=optimal_criterion_DT, max_features=optimal_max_features_DT, \n",
    "                            max_depth=optimal_max_depth_DT, random_state=0)\n",
    "DT.fit(X_train, y_train)\n",
    "\n",
    "# Using the dev data predict the y using decision tree algorithm\n",
    "y_dev_dec = DT.predict(X_dev)\n",
    "print(metrics.classification_report(y_dev, y_dev_dec))\n",
    "print(metrics.accuracy_score(y_dev, y_dev_dec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost\n",
    "\n",
    "AdaBoost is best used to boost the performance of decision trees on binary classification problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (adaboost with decision trees NORMAL new feature): 0.8895502645502645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.76      0.80       220\n",
      "           2       0.82      0.75      0.78       208\n",
      "           3       0.89      0.85      0.87       220\n",
      "           4       0.98      0.99      0.98       212\n",
      "           5       0.93      0.96      0.94       227\n",
      "           6       0.84      0.95      0.89       206\n",
      "           7       0.91      0.98      0.95       219\n",
      "\n",
      "    accuracy                           0.89      1512\n",
      "   macro avg       0.89      0.89      0.89      1512\n",
      "weighted avg       0.89      0.89      0.89      1512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_features = column_names_test.split(\",\")\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=20), n_estimators=500, learning_rate=1.0)\n",
    "abc.fit(X_train, y_train)\n",
    "y_pred = abc.predict(X_dev)\n",
    "print('Accuracy (adaboost with decision trees NORMAL new feature):', abc.score(X_dev,y_dev))\n",
    "print(classification_report(y_dev,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Decision tree and Adaboost to get the models\n",
    "DT.fit(train_df, train_labels_df)\n",
    "abc.fit(train_df, train_labels_df)\n",
    "\n",
    "# Supply the test_df to models and create predictions\n",
    "predictions_DT = DT.predict(test_df)\n",
    "predictions_abc = abc.predict(test_df)\n",
    "\n",
    "# converts predictions from np array to pd dataframe\n",
    "predictions_DT_df = pd.DataFrame(data = predictions_DT, index = test_data.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_abc_df = pd.DataFrame(data = predictions_abc, index = test_data.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "\n",
    "# outputs to csv file\n",
    "predictions_DT_df.to_csv(\"DT_predictions.csv\")\n",
    "predictions_abc_df.to_csv(\"abc_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When submitted DT into Kaggle the score was 0.672\n",
    "Post adaboost the score in Kaggle was 0.763"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
