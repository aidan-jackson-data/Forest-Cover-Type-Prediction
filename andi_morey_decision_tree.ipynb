{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)\n",
    "\n",
    "data = pd.read_csv(r\"data\\covtype.csv\")\n",
    "train_df = pd.read_csv(r\"data\\train.csv\")\n",
    "test_df = pd.read_csv(r\"data\\test.csv\")\n",
    "\n",
    "# Build the np arrays\n",
    "train_data = train_df.to_numpy()\n",
    "test_data = test_df.to_numpy()\n",
    "\n",
    "# Get last column for train labels\n",
    "train_labels = train_data[ :,55]\n",
    "\n",
    "#Remove last column from train_data because that is the labels\n",
    "train_data = np.delete(train_data, 55, axis=1)\n",
    "\n",
    "# Shuffle the input\n",
    "shuffle = np.random.permutation(np.arange(train_data.shape[0]))\n",
    "train_data, train_labels = train_data[shuffle], train_labels[shuffle]\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "#test_data, test_labels = train_data[0:2000,:], train_labels[0:2000]\n",
    "dev_data, dev_labels = train_data[2000:14000,:], train_labels[2000:14000]\n",
    "mini_train_data, mini_train_labels = train_data[14000:15000,:], train_labels[14000:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build new datasets for converting Soil_Types and Wilderness_Areas\n",
    "\n",
    "def binary_to_nominal(old_array):\n",
    "\n",
    "    column_to_be_added = np.ones(old_array.shape[0],int)\n",
    "    new_data = np.column_stack((old_array, column_to_be_added))\n",
    "\n",
    "    for i,row in enumerate(old_array):\n",
    "\n",
    "        new_data[i][new_data.shape[1]-1] = -1\n",
    "        soil_type = 0\n",
    "\n",
    "        for j, col in enumerate(data_columns):\n",
    "            if col[0:9] == \"Soil_Type\":\n",
    "                if new_data[i][j] == 1:\n",
    "                    soil_type = int(col[9:11])\n",
    "                    break\n",
    "\n",
    "        if soil_type > 0:\n",
    "            new_data[i][new_data.shape[1]-1] = soil_type\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "    cols_to_delete = []\n",
    "    for j, col in enumerate(data_columns):\n",
    "        if col[0:9] == \"Soil_Type\":\n",
    "            cols_to_delete.append(j)\n",
    "    new_data = np.delete(new_data, cols_to_delete, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    column_to_be_added = np.ones(new_data.shape[0],int)\n",
    "    new_data = np.column_stack((new_data, column_to_be_added))\n",
    "\n",
    "    for i,row in enumerate(old_array):\n",
    "\n",
    "        new_data[i][new_data.shape[1] - 1] = -1\n",
    "        wilderness_area = 0\n",
    "\n",
    "        for j, col in enumerate(data_columns):     \n",
    "            if col[0:15] == \"Wilderness_Area\":\n",
    "                if new_data[i][j] == 1:\n",
    "                    wilderness_area = int(col[15])\n",
    "                    break\n",
    "\n",
    "        if wilderness_area > 0:\n",
    "            new_data[i][new_data.shape[1]-1] = wilderness_area\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "    cols_to_delete = []\n",
    "    for j, col in enumerate(data_columns):\n",
    "        if col[0:15] == \"Wilderness_Area\":\n",
    "            cols_to_delete.append(j)\n",
    "    new_data = np.delete(new_data, cols_to_delete, axis=1)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "\n",
    "# Build the np arrays\n",
    "train_data2 = train_df.to_numpy()\n",
    "test_data2 = test_df.to_numpy()\n",
    "\n",
    "# Get last column for train labels\n",
    "train_labels2 = train_data2[ :,55]\n",
    "\n",
    "#Remove last column from train_data because that is the labels\n",
    "train_data2 = np.delete(train_data2, train_data2.shape[1]-1, axis=1)\n",
    "\n",
    "train_data2 = binary_to_nominal(train_data2)\n",
    "test_data2 = binary_to_nominal(test_data2)\n",
    "\n",
    "# Shuffle the input\n",
    "shuffle = np.random.permutation(np.arange(train_data2.shape[0]))\n",
    "train_data2, train_labels2 = train_data2[shuffle], train_labels2[shuffle]\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "#test_data2, test_labels2 = train_data2[0:2000,:], train_labels2[0:2000]\n",
    "dev_data2, dev_labels2 = train_data2[2000:14000,:], train_labels2[2000:14000]\n",
    "mini_train_data2, mini_train_labels2 = train_data2[14000:15000,:], train_labels2[14000:15000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "\n",
    "def print_importances(clf):\n",
    "    importances = np.round(clf.feature_importances_,4)\n",
    "    features = train_df.columns[0:55].to_numpy()\n",
    "    importances_df = pd.DataFrame({'feature':features,'importance':importances})\n",
    "    importances_df = importances_df.sort_values('importance',ascending=False)\n",
    "    importances_df = importances_df[(importances_df.sum(axis=1) != 0)]  \n",
    "    print(importances_df)\n",
    "    \n",
    "def print_structure(clf):\n",
    "    n_nodes = clf.tree_.node_count\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    feature = clf.tree_.feature\n",
    "    threshold = clf.tree_.threshold\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    print(\"The binary tree structure has {n} nodes and has the following tree structure:\\n\".format(n=n_nodes))\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            values = clf.tree_.value[i]\n",
    "            max_value = values.max()\n",
    "            cover_type = np.argmax(values)\n",
    "            print(\"{space}node={node} is a leaf node with max value of {value} and cover type of {ctype}\"\n",
    "                  .format(space=node_depth[i] * \"\\t\", node=i, value=max_value, ctype=cover_type))\n",
    "        else:\n",
    "            print(\"{space}node={node} is a split node: go to node {left} if {feature} <= {threshold} else to node {right}.\".format(\n",
    "                      space=node_depth[i] * \"\\t\",\n",
    "                      node=i,\n",
    "                      left=children_left[i],\n",
    "                      feature=train_df.columns[feature[i]],\n",
    "                      threshold=threshold[i],\n",
    "                      right=children_right[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desicion Tree Score: 64.74%\n",
      "Decision Tree Depth is 4 and has 16 leaves\n",
      "Confusion Matrix:\n",
      "\n",
      "[[1068  286    0    0  148    6  187]\n",
      " [ 420  641    4    1  569   73   13]\n",
      " [   0    1  717  326  112  565    0]\n",
      " [   0    0   92 1529    0  103    0]\n",
      " [   0   81    7    0 1530   94    0]\n",
      " [   0    8  407  206  144  933    0]\n",
      " [ 371    1    0    0    6    0 1351]]\n",
      "Desicion Tree Score: 66.03%\n",
      "Decision Tree Depth is 4 and has 16 leaves\n",
      "Confusion Matrix:\n",
      "\n",
      "[[1233   78    1    0  143    5  244]\n",
      " [ 740  339   17    1  567   60   28]\n",
      " [   0    1 1069  307  104  208    0]\n",
      " [   0    0  198 1516    0    9    0]\n",
      " [  21  101   48    0 1503   58    0]\n",
      " [   0    8  623  213  142  716    0]\n",
      " [ 146    0    0    0    6    0 1547]]\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "clf = clf.fit(train_data, train_labels)\n",
    "predicted_labels = clf.predict(dev_data)\n",
    "tree_model_score = clf.score(dev_data, dev_labels)\n",
    "depth = clf.get_depth()\n",
    "num_leaves = clf.get_n_leaves()\n",
    "\n",
    "print('Desicion Tree Score: %.2f%%' % (tree_model_score*100))   \n",
    "print('Decision Tree Depth is %d and has %d leaves' % (depth, num_leaves))\n",
    "\n",
    "#plt.figure(figsize=(75,10))\n",
    "#tree.plot_tree(clf, feature_names=train_df.columns, proportion=True)\n",
    "#plt.show()\n",
    "#print_importances(clf)\n",
    "#print_structure(clf)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(dev_labels, predicted_labels))\n",
    "\n",
    "\n",
    "\n",
    "### With new data\n",
    "clf2 = tree.DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "clf2 = clf2.fit(train_data2, train_labels2)\n",
    "predicted_labels = clf2.predict(dev_data2)\n",
    "tree_model_score = clf2.score(dev_data2, dev_labels2)\n",
    "depth = clf2.get_depth()\n",
    "num_leaves = clf2.get_n_leaves()\n",
    "\n",
    "print('Desicion Tree Score: %.2f%%' % (tree_model_score*100))   \n",
    "print('Decision Tree Depth is %d and has %d leaves' % (depth, num_leaves))\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(dev_labels2, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal value for depth using GridSearchCV method is 25 with accuracy of 0.9978333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15121</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15122</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15123</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15125</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581012</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565892 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cover_Type\n",
       "Id                \n",
       "15121            5\n",
       "15122            5\n",
       "15123            5\n",
       "15124            5\n",
       "15125            5\n",
       "...            ...\n",
       "581008           3\n",
       "581009           3\n",
       "581010           3\n",
       "581011           3\n",
       "581012           6\n",
       "\n",
       "[565892 rows x 1 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "depths = {\"max_depth\": [3, 4, 5, 10, 25, 30]}\n",
    "\n",
    "#Grid search is not working as expected.  Keeps claming the second to last is better even though it is not...\n",
    "grid_search_decision_tree = GridSearchCV(tree.DecisionTreeClassifier(), depths, scoring='accuracy')\n",
    "grid_search_decision_tree.fit(train_data, train_labels)\n",
    "predicted = grid_search_decision_tree.predict(dev_data)\n",
    "optimal_depth = grid_search_decision_tree.best_params_['max_depth']\n",
    "print(\"The optimal value for depth using GridSearchCV method is {depth} with accuracy of {accuracy}\"\n",
    "      .format(depth=optimal_depth, accuracy=metrics.accuracy_score(dev_labels, predicted)))\n",
    "\n",
    "clf_final = tree.DecisionTreeClassifier(max_depth=25, random_state=0)\n",
    "clf_final = clf_final.fit(train_data, train_labels)\n",
    "test_predictions = clf_final.predict(test_df)\n",
    "\n",
    "predictions_dt = pd.DataFrame(data = test_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_dt.to_csv(\"dt_predictions.csv\")  #Kaggle Score of 0.59266\n",
    "predictions_dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15121</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15122</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15123</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15125</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581012</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565892 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cover_Type\n",
       "Id                \n",
       "15121            2\n",
       "15122            1\n",
       "15123            2\n",
       "15124            2\n",
       "15125            2\n",
       "...            ...\n",
       "581008           3\n",
       "581009           3\n",
       "581010           3\n",
       "581011           3\n",
       "581012           3\n",
       "\n",
       "[565892 rows x 1 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat on new data set\n",
    "depths = {\"max_depth\": [3, 4, 5, 10, 25, 30]}\n",
    "\n",
    "# #Grid search is not working as expected.  Keeps claming the second to last is better even though it is not...\n",
    "# grid_search_decision_tree = GridSearchCV(tree.DecisionTreeClassifier(), depths, scoring='accuracy')\n",
    "# grid_search_decision_tree.fit(train_data2, train_labels2)\n",
    "# predicted = grid_search_decision_tree.predict(dev_data2)\n",
    "# optimal_depth = grid_search_decision_tree.best_params_['max_depth']\n",
    "# print(\"The optimal value for depth using GridSearchCV method is {depth} with accuracy of {accuracy}\"\n",
    "#       .format(depth=optimal_depth, accuracy=metrics.accuracy_score(dev_labels2, predicted)))\n",
    "\n",
    "clf_final = tree.DecisionTreeClassifier(max_depth=30, random_state=0)\n",
    "clf_final = clf_final.fit(train_data2, train_labels2)\n",
    "test_predictions = clf_final.predict(test_data2)\n",
    "\n",
    "predictions_dt = pd.DataFrame(data = test_predictions, index = test_df.loc[:, \"Id\"], columns = [\"Cover_Type\"])\n",
    "predictions_dt.to_csv(\"dt_predictions.csv\")  #Kaggle Score of 0.59169\n",
    "predictions_dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8567499999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd = RandomForestClassifier()\n",
    "rnd.fit(train_data,train_labels)\n",
    "print(cross_val_score(rnd,dev_data,dev_labels,cv = 3).mean())\n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from  sklearn.ensemble import AdaBoostClassifier\n",
    "ex = ExtraTreesClassifier(random_state  =123,n_estimators = 1000)\n",
    "ex1 = AdaBoostClassifier(base_estimator = ex,n_estimators = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
